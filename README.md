# Robotic Project
# Warehouse Robot
<img src="https://github.com/user-attachments/assets/dcd70d99-d0f7-4ab6-9b08-57bd2034f979" alt="description" width="800"/>
<img src="https://github.com/user-attachments/assets/988e52fd-9066-4501-87d0-776e88a2e824" alt="description" width="800"/>
<img src="https://github.com/user-attachments/assets/5ad2d584-fbfd-4366-b079-c4a24f78387b" alt="Animated GIF" width="300"/>

## Achievement
This project was the top-performing project of the term, earning the highest score in the Computer Artichucture course at Shahid Bahonar University of Kerman. The implementation quality and innovative solutions contributed to its recognition as the best project.
#### Supervisor:
Dr. Jamshidi

## Executives:
Hiva AbolhadiZadeh - Amirhossein Abolhasani -Kimia Mashhadi Zadeh - Sadra Kochakzadeh

## Introduction to the Robot and its Objective:
In an era of technological advancement and commerce, warehouse management has become one of the most marginalized and evolving areas. One of the most captivating developments in this regard is the introduction of warehouse robots, which have emerged as representatives
of technological advancement in this field. These intelligent devices, utilizing artificial intelligence, the Internet of Things, and advanced sensors, have evolved into a powerful combination of intelligence, precision, and speed.

## Advantages of a Warehouse Robot:
1. Increased Productivity:
Warehouse robots, with their intelligent capabilities, have enhanced the productivity of various warehouse processes. This increase in productivity not only reduces the time and costs associated with warehouse operations but also increases the ability to perform tasks simultaneously and more quickly.
2. High Precision:
Warehouse robots, utilizing barcode scanning technology and sensors, exhibit high precision in identifying and recording products. This precision reduces human errors in inventory management and order fulfillment.
3. Cost Reduction:
Increased productivity and precision lead to a reduction in operational costs associated with warehouse management. Robots play a significant role as the primary driver of business efficiency improvement.
4. Technological Transformation in Warehouse Management:
Technologies such as artificial intelligence, the Internet of Things (IoT), and machine learning have gradually entered the field of warehouse management. These advancements greatly facilitate the optimization of warehouse processes. Smart warehouses, with the ability to connect to other networks and exchange data, enable better inventory management, demand forecasting, and waste reduction. As a significant advancement in supply chain management, these technological transformations signify a bright future for improving warehouse processes and enhancing efficiency in organizations. Warehouse robots, with all their capabilities, symbolize the endless potential of technology in enhancing the efficiency and performance of modern warehouses.

## Introduction to the Functions of the Warehouse Robot:
Our team has devoted considerable effort and dedication to building an advanced version of the warehouse robot, which not only meets the basic needs of a warehouse and warehouse manager but also assists warehouse operators in intelligently and optimally managing the status of goods, inventory, and robot operation processes by upgrading warehouse processes.

## Main Objective of the Project:
The main objective of building this robot is to facilitate warehouse processes. As an intelligent collaborator, this robot is capable of performing tasks such as automatic or manual movement of boxes and loads. Additionally, this project has provided a mobile application that warehouse operators can easily use to communicate with the robot and monitor its operation status.

## Primary Functions of the Warehouse Robot:

1. Moving Loads: The warehouse robot is capable
of automatically or manually moving boxes and
loads. This feature helps warehouse operators
quickly and efficiently transport loads to their
intended destinations.

2. Inventory Checking: Using sensors and
advanced technologies, the robot can check the
inventory in the warehouse and provide
warehouse operators with accurate information
about the status of products in stock.

3. Warehouse Temperature Control: The robot has
the ability to control the temperature in the
warehouse and can assist in adjusting the
ambient temperature if necessary.

4. Warehouse Humidity Control: By using a
humidity control system, the warehouse robot
provides the capability to manage and monitor
the humidity level in the environment.

5. Smoke Detection Alert: Equipped with smoke
sensors, the warehouse robot can send an alert
to the mobile application or notify the warehouse
operators in case of smoke detection.

This initial version of the warehouse
robot is designed to address the basic
needs of a warehouse and warehouse
manager. With the continuation of the
project and the development of the
robot, it is expected that by adding
features and necessary improvements, it
will evolve into a smarter and more
efficient tool. This version is just the first
step towards improving warehouse
processes and our team will be diligently
working with full energy to advance the
project and further enhance the robot's
functionality and usability.
![Screenshot 2024-01-28 200215](https://github.com/user-attachments/assets/cfce0ea5-90e7-4b1d-8e76-a12481947728)


## project roadmap:
![Screenshot 2024-01-28 201845](https://github.com/user-attachments/assets/1062cdfb-724d-421b-86b1-d98eb2050760)

## Designing and constructing the power management:
<img src="https://github.com/user-attachments/assets/0bfa93e7-e943-4364-99a0-31ccbd067d30" alt="description" width="400"/>
<img src="https://github.com/user-attachments/assets/a0bce3a5-2ace-40d4-aa1e-6a2f1099725c" alt="description" width="400"/>

1. First, we print the circuit diagram of the power
management on a glass-coated paper with
dimensions of 10*10
2. Then, we scratch the fiberglass with a wire and
print the circuit diagram onto the fiberglass using
an iron. To ensure better adhesion of the paper
onto the fiberglass, it's better to first heat the
surface with the iron. The more pressure applied
by the iron onto the fiberglass, the better the ink
will adhere to it.
3. Afterward, to separate the paper, we
immerse the fiberglass in water and peel off
the paper. Following the separation of the
papers, we soak the fiberglass in tea acid to
ensure that only the circuit design remains
on it.
4. After separating the papers, we immerse the
fiberglass in tea acid so that only the circuit
the design remains on it.
5. After that, we place the components on the board
using a regular drill with a 1mm drill bit and solder
the components onto the board. Soldering starts
with low-profile components like resistors or diodes
and ends with components like Tip2259. If your
board is bone-shaped, use a 40w soldering iron. For
components requiring heat sinking like Tip2259, first,
connect the heat sink to the component and then
the solder.
<img src="https://github.com/user-attachments/assets/e830e852-190e-4d38-9ba2-9d5d8fa03d9a" alt="description" width="400"/>

## Sensors:
In building this robot, we have used
three sensors: DHT11, MQ2, and ultrasonic. You can see how we program sensors and the codes on this repository.
We used DC gearbox motors. Initially, we measured the
current by applying pressure to the pulling motor using a
power source. Then, after connecting the wheels to the
motor, we supplied input to the L298 and noted the
wheel rotation direction by giving manual flags.

## Body construction and component placement
Body Construction:

Materials: Choose strong, lightweight materials such as aluminum or high-strength plastics.
Design: Ensure the robot is compact for navigation while being sturdy enough for warehouse use.
Component Placement:

Sensors: Place sensors and cameras for 360-degree visibility and obstacle detection.
Manipulators: Position manipulators to maximize reach and efficiency.
Power Supply: Locate the battery to maintain balance and allow easy access for maintenance.
As this was our first robot project, we aimed to adhere closely to these guidelines to achieve optimal performance and reliability.

![image](https://github.com/user-attachments/assets/2d87c840-5ed5-41c1-b69e-8d2a1393f114)

## mobile app:
Flutter UI design
Stage One: Designing the
App Sketch in Figma
The app was designed in five
pages, where all elements
are placed together for ease
of use. Efforts were made to
employ pastel colors and
gentle shades of green, red,
and blue, which are the
colors of the robot, to make
working with the robot easy
.and enjoyable for the user.
UI Programming:
Stage Two - Programming
In the first stage, you need to
install the Dart and Flutter
packages along with the Android
SDK. Then, using the IDE and the
VS code, you can start coding the
UI part.
Widgets in the app are arranged in
a row-column layout, where each
page should have a single column,
and the desired widgets should be
placed in each row.
For the navigation bar section, all
definitions should be made in the
common class on the main page
so that the navigation between
pages can be facilitated.
##### Page One:
For the IP change conditions, we
have included an input box so that the user
is prompted to enter the desired server IP
as soon as they enter. After specifying the
number of boxes that need to be detected
and moved, the user must enter them in the
designated input. By pressing the save
button, the entered information about the
boxes is transferred to the entity page.
Pressing the reset button sets the number
of boxes to zero, and the user must enter
the box count again.

<img src="https://github.com/user-attachments/assets/fe9fbf54-a6a1-4553-8765-855c62ad8e77" alt="description" width="200"/>


##### Page Two: 
This page is designed for
manual control of the robot, where
the robot moves boxes around and
picks them up or drops them using
buttons. The blue box in the image
also displays the view from the
robot's perspective.

<img src="https://github.com/user-attachments/assets/d4447d51-c2af-4472-b27b-17ed92333bce" alt="description" width="200"/>


##### Page Three:
This page represents
automatic movement, where the
the robot automatically detects boxes
and moves them to the desired
destination. The blue box in the
image indicates the view from the
robot's perspective.

<img src="https://github.com/user-attachments/assets/c47f6859-a5cb-4300-80d4-6ce744072f82" alt="description" width="200"/>


##### Page Four:
This page displays
entities, and for each box placed by
the robot, a numerical value is
incremented by the number
assigned to the box.

<img src="https://github.com/user-attachments/assets/6483f703-a072-44aa-914e-b9f936c1c2be" alt="description" width="200"/>


##### Page Five: 
The sensor page functions
by retrieving humidity and
temperature values from the
Raspberry Pi and sending them to the
application, displaying them in
designated sections. The last sensor
pertains to a smoke detection sensor.
In the event of smoke detection, an
alert symbol appears next to the
sensor as a warning.

<img src="https://github.com/user-attachments/assets/d138121c-348b-433a-9ea1-b41c424866d5" alt="description" width="200"/>

## Image processing:
![image](https://github.com/user-attachments/assets/28e6c7ce-06e5-4dd8-9509-4dccca09e8ff)

#### Method for detecting boxes (detect_box)
In this method, a technique for finding
boxes and outputting frames is
implemented. The general algorithm of
this method is as follows:
1. Resize the captured frame.
2. Remove image noise.
3. Convert the frame color system to HSV.
4. Filter out all colors in the frame except
for the box color using upper HSV and
lower HSV.
5. Find image contours.
6. Extract the contour with the largest area
among the found contours.
7. Find the smallest enclosing rectangle
around the contour.
8. Draw the rectangle with its center on the
frame.
9. Draw guidelines on the frame.
10. Output the image.
11. Output the rectangle center.
12. Output the rectangle size.
13. Output information about the frame
(frame center, frame length, and width, ...).


#### Method for finding the placement location
of the box (detect_sign)
In this method, we identify the sign in front
of which the ball grabbed by the robot is
placed. The general algorithm of this
method is as follows:
1. Resize the captured frame.
2. Image noise removal.
3. Convert the frame color system to HSV.
4. Filtering out all colors in the frame except for the box color using the upper HSV and lower HSV.
5. Finding image contours.
6. Extracting the contour with the largest area among the found contours.
7. Finding the smallest enclosing circle around the contour.
8. Draw the circle with its center on the frame.
9. Drawing guidelines on the frame.
10. Outputting the image.
11. Outputting the circle center.
12. Outputting the circle radius.
13. Outputting information about the frame (frame center, frame length, width, ...).

## How to run:
Make sure you have `python` installed on your system. Instal the required dependency by running `pip install -r requirements.txt` in your terminal.
